{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lm-rec ECIR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBQ7A3HFQSdy2Q732ljjNI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sileod/Zero-Shot-Recommendation-with-Language-Modeling/blob/main/lm_rec_ECIR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Huggingface dataset"
      ],
      "metadata": {
        "id": "Lcldtb7c-2Bu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://huggingface.co/datasets/sileod/movie_recommendation"
      ],
      "metadata": {
        "id": "pqeng7GA_F3M"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih_YzZd6SDB5"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2437VdU6P7_w"
      },
      "source": [
        "!pip install GPUtil dropbox xpflow wandb wget -q &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20YBuD7jJNVI"
      },
      "source": [
        "!pip install git+https://github.com/google/BIG-bench.git -q &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOcZ6jYBLGEy"
      },
      "source": [
        "from xpflow import Xp\n",
        "from bigbench.api import json_task\n",
        "import bigbench.models.huggingface_models as huggingface_models\n",
        "import bigbench.api.model as api_model\n",
        "from tensorflow.keras import mixed_precision\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import functools\n",
        "import json\n",
        "from tqdm.auto import tqdm\n",
        "from datetime import datetime\n",
        "import sklearn\n",
        "from easydict import EasyDict as edict \n",
        "from collections import defaultdict\n",
        "from itertools import chain\n",
        "import hashlib\n",
        "import wget,zipfile, os\n",
        "import wandb\n",
        "from appdirs import user_data_dir\n",
        "import pathlib\n",
        "\n",
        "\n",
        "def precision_recall(y_true,y_pred,k):\n",
        "  nz = pd.DataFrame(y_true.nonzero()).T\n",
        "  nz.columns = ['user','item']\n",
        "  nz = np.array(list(nz.groupby('user')['item'].agg(list)))\n",
        "\n",
        "  precision,recall=[],[]\n",
        "  for true,pred in zip(nz, (-y_pred).argsort(axis=1)[:,:k]):\n",
        "    u_recall=np.mean([x in pred for x in true])\n",
        "    u_precision=np.mean([x in true for x in pred])\n",
        "    precision+=[u_precision]\n",
        "    recall+=[u_recall]\n",
        "  return {f'precision_{k}':np.mean(precision), f'recall_{k}':np.mean(recall)}\n",
        "\n",
        "def make_metrics(y_true, y_pred):\n",
        "  metrics=defaultdict(list)\n",
        "  for k in [1,2,3,4,5]:\n",
        "    for i in range(len(y_true)):\n",
        "      yt, yp = y_true[[i],:], y_pred[[i],:]\n",
        "      metrics[f'ndcg_{k}']+=[sklearn.metrics.ndcg_score(y_true=yt, y_score=yp,k=k)]\n",
        "      metrics[f'precision_{k}']+=[precision_recall(yt,yp,k)[f'precision_{k}']]\n",
        "      metrics[f'recall_{k}']+=[precision_recall(yt,yp,k)[f'recall_{k}']]\n",
        "\n",
        "  for m in list(metrics.keys()):\n",
        "    metrics[f'{m}_std']=np.std(metrics[m])\n",
        "    metrics[m]=np.mean(metrics[m])\n",
        "\n",
        "  return dict(metrics)\n",
        "\n",
        "def make_pop(y_pred, y_pops):\n",
        "  pop_1=[]\n",
        "  for pops, i in zip(y_pops, y_pred.argmax(axis=1)):\n",
        "    pop_1+=[pops[i]]\n",
        "  return {'pop_1':np.mean(pop_1), 'pop_1_std':np.std(pop_1)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTmFZW-gSIak"
      },
      "source": [
        "# Build data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7xksXrCCnNd"
      },
      "source": [
        "root = pathlib.Path(user_data_dir(\"gpt-rec\"))\n",
        "root.mkdir(exist_ok=True)\n",
        "os.chdir(root)\n",
        "url = 'https://files.grouplens.org/datasets/movielens/ml-1m.zip'\n",
        "\n",
        "if not os.path.exists('ml-1m'):\n",
        "    filename = wget.download(url)\n",
        "    zipfile.ZipFile(filename).extractall()\n",
        "os.chdir('ml-1m')\n",
        "\n",
        "def process_movielens_name(s):\n",
        "    s=s[:-7]\n",
        "    s=s.split(' (')[0]\n",
        "    for pattern in [', The',', A']:\n",
        "      if s.endswith(pattern):\n",
        "        s=pattern.split(', ')[1]+' ' + s.replace(pattern,'')\n",
        "    return s\n",
        "\n",
        "items = pd.read_csv('movies.dat',sep='::',names=['movieId','title','genres'], engine='python',encoding=\"latin-1\")\n",
        "items['name'] = items.title.map(process_movielens_name)\n",
        "item_id_to_name = items.set_index('movieId')['name'].to_dict()\n",
        "\n",
        "prompts = ('[M]',#0\n",
        "'Movies like [M]',#1\n",
        "'Movies similar to [M]',#2\n",
        "'Movies like: [M]',#3\n",
        "'Movies similar to: [M]',#4\n",
        "'If you liked [M] you will also like')#5\n",
        "\n",
        "def make_prompt(l, xp):\n",
        "  movies = xp.sep.join(random.sample([item_id_to_name[i] for i in l], xp.nb_pos))\n",
        "  prompt = prompts[xp.prompt_id].replace('[M]', movies) \n",
        "  return prompt + xp.end_sep\n",
        "\n",
        "def make_data(xp):\n",
        "  df = pd.read_csv('ratings.dat',sep=\"::\", names=['userId','movieId','rating','ts'], engine='python')\n",
        "  df=df[~df.rating.between(2.4,4.1)]\n",
        "  R = df.pivot('movieId','userId','rating')\n",
        "\n",
        "  pos_neg = df.groupby('userId')['movieId'].agg(list).reset_index().sample(frac=1.0, random_state=xp.users_seed)\n",
        "  pos_neg[\"pos\"]=pos_neg.apply(lambda x: [i for i in x.movieId if R[x.userId][i]>xp.like_threshold], axis=1)\n",
        "  pos_neg[\"neg\"]=pos_neg.apply(lambda x: [i for i in x.movieId if R[x.userId][i]<xp.dislike_threshold], axis=1)\n",
        "  pos_neg=pos_neg.set_index('userId')\n",
        "  pos_neg=pos_neg[pos_neg.pos.map(len).ge(xp.min_pos_ratings)]\n",
        "  pos_neg=pos_neg[pos_neg.neg.map(len).ge(xp.min_neg_ratings)]\n",
        "\n",
        "  pos_neg['support'] = pos_neg.pos.map(lambda x: random.sample(x, xp.nb_pos+1))\n",
        "  pos_neg['targets'] = pos_neg.support.map(lambda x:[x[-1]]) + pos_neg.neg.map(lambda x: random.sample(x, xp.nb_neg))\n",
        "  pos_neg['support']= pos_neg['support'].map(lambda x:x[:-1])\n",
        "  pos_neg['choices']= pos_neg.targets.map(lambda l: tuple([item_id_to_name[i] for i in l]))\n",
        "  pos_neg['prompt']= pos_neg.support.map(lambda l:make_prompt(l, xp))\n",
        "\n",
        "  pop=(R.sum(axis=1) / (R.T.sum().mean())).to_dict()\n",
        "  pos_neg['pop']=pos_neg.targets.map(lambda l: [pop[x] for x in l])\n",
        "\n",
        "  return pos_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hc1fCKhgZAOa"
      },
      "source": [
        "from transformers import BertForPreTraining, AutoTokenizer\n",
        "\n",
        "class BERT:\n",
        "  def __init__(self,args):\n",
        "    self.tokenizer=AutoTokenizer.from_pretrained(args.model_type)\n",
        "    self.model=BertForPreTraining.from_pretrained(args.model_type)\n",
        "    self._model = edict(_model_name=args.model_type)\n",
        "  def cond_log_prob(self, inputs, targets):\n",
        "    inputs, targets = [inputs]*len(targets), list(targets)\n",
        "    scores= self.model(**self.tokenizer(inputs, targets, \n",
        "      return_tensors='pt',padding=True)).seq_relationship_logits\n",
        "    return list(scores[:,0].cpu().detach().numpy())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwsRIIDJN5tr"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtPcAF9iNB1_"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "class base(Xp):\n",
        "  like_threshold=4\n",
        "  dislike_threshold=2.5\n",
        "  min_pos_ratings = 21\n",
        "  min_neg_ratings = 5\n",
        "  nb_pos=5\n",
        "  nb_neg=4\n",
        "  prompts=str(prompts)\n",
        "  prompt_id = [0,3]\n",
        "  data_path = os.getcwd()\n",
        "  model_type = 'gpt2'\n",
        "  nb_test_users=50\n",
        "  users_seed = 0\n",
        "  sep=','\n",
        "  end_sep=','\n",
        "  offset=[0,50,100,150]\n",
        "\n",
        "class model_size(base):\n",
        "  model_type = ['gpt2', 'gpt2-medium', 'gpt2-large'][::-1]\n",
        "\n",
        "class nb_pos(base):\n",
        "  nb_pos=[1,2,3,5,7,10,15,20]\n",
        "\n",
        "class prompts_types(base):\n",
        "  prompt_id=[0,1,2,3,4,5]\n",
        "  #sep=[', ','\\n']\n",
        "\n",
        "class penha(base):\n",
        "  prompt_id=5\n",
        "  end_sep=\" \"\n",
        "  model_type=['bert-base-uncased', 'bert-large-uncased']\n",
        "\n",
        "\n",
        "for xp in tqdm(list(chain(*[x() for x in [\n",
        "  nb_pos,                                \n",
        "]\n",
        "  ]))):\n",
        "  xp_hash = f'{hash(xp)}.txt'\n",
        "  if xp_hash in {x.name for x in dbx.files_list_folder('/colab/log').entries}:\n",
        "    continue\n",
        "\n",
        "  run = wandb.init(project='gpt-rec', entity='',reinit=True, config=xp);\n",
        "  pos_neg = make_data(xp)\n",
        "  if 'bert' in xp.model_type:\n",
        "    model = BERT(xp)\n",
        "  else:\n",
        "    model = huggingface_models.BIGBenchHFModel(xp.model_type)\n",
        "  l=[]\n",
        "  users = list(range(xp.offset,xp.offset+xp.nb_test_users))\n",
        "  for i in tqdm(users):\n",
        "    scores = model.cond_log_prob(\n",
        "        inputs=list(pos_neg.prompt)[i],\n",
        "        targets=list(pos_neg.choices)[i]\n",
        "        )\n",
        "    l+=[scores]\n",
        "  y_pred = np.array(l)\n",
        "  y_true = y_pred*0\n",
        "  y_true[:,0]=1\n",
        "  xp.result = make_metrics(y_true, y_pred)\n",
        "  wandb.log(xp.result)\n",
        "  wandb.log(make_pop(y_pred, pos_neg.iloc[users]['pop']))\n",
        "  run.finish()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}